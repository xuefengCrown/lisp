# chapter2 

The program works fine, and the trace looks just like the sample derivation above,
but the Lisp definitions are a bit harder to read than the original grammar rules.
This problem will be compounded as we consider more complex rules. Suppose we
wanted to allow noun phrases to be modified by an indefinite number of adjectives
and an indefinite number of prepositional phrases. In grammatical notation, we
might have the following rules:
Noun-Phrase ==> Article  +  Adj*  +  Noun  +  PP*
Adj* ==> 0,  Adj  +  Adj*
PP* ==> 0,PP+PP*
PP ==> Prep  +  Noun-Phrase
Adj ==> big, little, blue, green,  . . .
Prep ==> to, in, by, with,  . .  .
In this notation,  0  indicates a choice of nothing at all, a comma indicates a choice of
several alternatives, and the asterisk is nothing special - as in Lisp, it's just part of the
name of a symbol. However, the convention used here is that names ending in an
asterisk denote zero or more repetitions of the underlying name. That is,  PP*  denotes
zero or more repetitions of  PP.  This is known as "Kleene star"  notation (pronounced
"clean-E") after the mathematician Stephen Coleleen.

The problem is that the rules for  Adj "  and  PP "  contain choices that we would have
to represent as some kind of conditional in Lisp. For example:
(defun Adj* ()
  (if (= (random 2) 0)
      nil
      (append (Adj (Adj*))))
  
(defun PP* ()
  (if (random-elt '(t  nil))
      (append  (PP)  (PP*))
      nil))
      
(defun noun-phrase () (append (Article) (Adj*) (Noun) (PP*)))
(defun PP () (append (Prep) (noun-phrase)))
(defun Adj () (one-of '(big little blue green adiabatic)))
(defun Prep () (one-of '(to in by with on)))

I've chosen two different implementations for  Adj*  and  PP*;  either approach would
work in either function. We have to be careful, though; here are two approaches that
would not work:
(defun Adj* ()
  "Warning-incorrect definition of Adjectives."
  (one-of '(nil (append (Adj) (Adj*)))))

(defun Adj* ()
  "Warning-incorrect definition of Adjectives."
  (one-of (list nil (append (Adj) (Adj*)))))

The first definition is wrong because it could return the literal expression  ((append
(Adj) (Adj*))) rather than a list of words as expected. The second definition would
cause infinite recursion, because computing the value of  (Adj*) always involves a
recursive call to  (Adj*).

The point is that what started out as simple functions are now becoming quite complex. 
To understand them, we need to know many Lisp conventions - defun, (),  case,  
if, quote, and the rules for order of evaluation - when
ideally the implementation of a grammar rule should use only  linguistic  conventions.
If we wanted to develop a larger grammar, the problem could get worse, because the
rule - writer might have to depend more and more on Lisp.

## 2.3 A Rule-Based Solution
基于规则的解决方案

An alternative implementation of this program would concentrate on making it easy
to write grammar rules and would worry later about how they will be processed.
Let's look again at the original grammar rules:

Sentence ==> Noun-Phrase + Verb-Phrase
Noun-Phrase ==> Article + Noun
Verb-Phrase ==> Verb + Noun-Phrase
Article ==> the, a, ...
Noun ==> man, ball, woman, table...
Verb ==> hit, took, saw, liked...


Each rule consists of an arrow with a symbol on the left - hand side and something on
the right - hand side. The complication is that there can be two kinds of right - hand
sides: a concatenated list of symbols, as in  "Noun-Phrase ==> Article + Noun,"  or a list of
alternate words, as in "Noun ==> man, ball, ..."  We can account for these possibilities
by deciding that every rule will have a list of possibilities on the right - hand side, and
that a concatenated list, for example "Article + Noun,"  will be represented as a Lisp list,
fir example "(Article Noun)".  The list of rules can then be represented as follows:
(defparameter *simple-grammar*
  '((sentence -> (noun-phrase verb-phrase))
  (noun-phrase -> (Article Noun))
  (verb-phrase -> (Verb noun-phrase))
  (Article -> the a)
  (Noun -> man ball woman table)
  (Verb -> hit took saw liked))
  "A grammar for a trivial subset of English.")
  
(defvar *grammar* *simple-grammar*
"The grammar used by generate. Initially, this is
*simple-grammar*, but we can switch to other grammars.")

Note that the Lisp version of the rules closely mimics the original version. 
In particular, I include the symbol  "->", even though it serves no real purpose; 
it is purely decorative.

The special forms defvar and defparameter both introduce special variables
and assign a value to them; the difference is that a variable, like *grammar*, is
routinely changed during the course of running the program.  A  parameter, like
*simple-grammar*, on the other hand, will normally stay constant.  A change to a
parameter is considered a change to the program, not a change  by  the program.
Once the list of rules has been defined, it can be used to find the possible rewrites
of a given category symbol. The function assoc is designed for just this sort of task.

It takes two arguments, a "key" and a list of lists, and returns the first element of the
list of lists that starts with the key. If there is none, it returns nil. Here is an example:

CL-USER> (assoc 'verb *simple-grammar*)
(VERB -> HIT TOOK SAW LIKED)


Although rules are quite simply implemented as lists, it is a good idea to impose a
layer of abstraction by defining functions to operate on the rules. We will need three
functions: one to get the right-hand side of a rule, one for the left-hand side, and one
to look up all the possible rewrites (right-hand sides) for a category.
(defun rule-lhs (rule)
"The left-hand side of a rule."
  (first rule))

(defun rule-rhs (rule)
"The right-hand side of a rule."
  (rest (rest rule)))
  
(defun rewrites (category)
"Return a list of the possible rewrites for this category. "
  (rule-rhs (assoc category *grammar*)))

CL-USER> (rule-lhs (assoc 'verb *simple-grammar*))
VERB
CL-USER> (rule-rhs (assoc 'verb *simple-grammar*))
(HIT TOOK SAW LIKED)

CL-USER> (rewrites 'noun-phrase)
((ARTICLE NOUN))
CL-USER> (rewrites 'verb)
(HIT TOOK SAW LIKED)


We are now ready to address the main problem: defining a function that will
generate sentences (or nounphrases, or any other category). We will call this function
generate.  It will have to contend with three cases:  (1)  In the simplest case,  generate
is passed a symbol that has a set of rewrite rules associated with it. We choose one of
those at random, and then generate from that.  (2)  If the symbol has no possible rewrite
rules, it must be a terminal symbol - a word, rather than a grammatical category - and
we want to leave it alone. Actually, we return the list of the input word, because, as
in the previous program, we want all results to be lists of words.  (3)  In some cases,
when the symbol has rewrites, we will pick one that is a list of symbols, and try to
generate from that. Thus,  generate  must also accept a list as input, in which case
it should generate each element of the list, and then append them all together. In
the following, the first clause in  generate  handles this case, while the second clause
handles  (1)  and the third handles  (2).  Note that we used the  mappend  function from
section 1.7 (page 18).

(defun generate (phrase)
"Generate a random sentence or phrase"
  (cond ((listp phrase)
            (mappend #'generate phrase))
        ((rewrites phrase)
            (generate (random-elt (rewrites phrase))))
        (t (list phrase))))

(defun one-of (set)
"Pick one element of set, and make a 1ist of  it."
  (list (random-elt set)))
  
(defun random-elt (choices)
"Choose an element from a list at random."
  (elt choices (random (length choices))))

Like many of the programs in this book, this function is short, but dense with
information: the craft of programming includes knowing what not to write, as well
as what to write.
This style of programming is called  data-driven programming（数据驱动编程）, because the data
(the list of rewrites associated with a category) drives what the program does next. It
is a natural and easy-to-use style in Lisp, leading to concise and extensible programs,
because it is always possible to add a new piece of data with a new association without
having to modify the original program.
数据驱动编程是Lisip中自然，容易使用的风格，带来简洁又易扩展的程序，因为我们总是能够在
不修改源程序的情况下添加新数据。
Here are some examples of generate in use:
>  (generate 'sentence)  ==>  (THE TABLE SAW THE BALL)
>  (generate 'sentence)  ==> (THE WOMAN HIT A TABLE)
>  (generate 'noun - phrase)  ==>  (THE MAN)
>  (generate 'verb-phrase)  ==>  (TOOK A TABLE)


let is the most common way of introducing variables that are not parameters of
functions. 

(defun generate (phrase)
  (setf choices ...) ;; wrong!
  ... choices ...
  
This is wrong because the symbol choices now refers to a special or global variable,
one that may be shared or changed by other functions. Thus, the function  generate
is not reliable, because there is no guarantee that choices will retain the same value
from the time it is set to the time it is referenced again. With  let we introduce a brand
new variable that nobody else can access; therefore it is guaranteed to maintain the
proper value.

！！！非常重要！！！
## 2.4 Two Paths to Follow
上面的程序的两种版本代表了两种方法，它们在开发程序的过程中一再出现：
1） 将问题描述最直接的映射进Lisp代码。
2） 使用可解决问题的最自然的符号/记号，然后只要考虑为这些记号写个解释器。！！！！！！！！！！！！
The two versions of the preceding program represent two alternate approaches that
come up time and time again in developing programs:  
(1) Use the most straightfor-ward mapping of the problem description directly into Lisp code. 
(2) Use the most natural notation available to solve the problem, and then worry about writing an
interpreter for that notation.
方法2引入了额外的步骤，所以对于解决小问题来说增加了一些工作。
然而，使用这种方法写得程序更容易修改和扩展。尤其适用于有大量数据要account for的domain。
自然语言的语法就是这样的一个域——实际上，大多数的AI问题都适合这个描述。
方法2背后的思想是，尽可能用它本身的术语来解决该问题，要最小化写在Lisp中的部分。（???）
Approach (2) involves an extra step, and thus is more work for small problems.
However, programs that use this approach are often easier to modify and expand.
This is especially true in a domain where there is a lot of data to account for. The
grammar of natural language is one such domain-in fact, most AI problems fit this
description. The idea behind approach  (2)  is to work with the problem as much as
possible in its own terms, and to minimize the part of the solution that is written
directly in Lisp.
幸运的是，在Lisp中设计新的记号是很容易的——该新记号实际上是新的编程语言。
因此，Lisp促进了更健壮程序的构建。
贯穿本书，我们都会提到两种方法。读者将注意到，大部分示例中我们选择第2种方法。
Fortunately, it is very easy in Lisp to design new notations - in effect, new programming languages. 
Thus, Lisp encourages the construction of more robust programs.
Throughout this book, we will be aware of the two approaches. The reader may
notice that in most cases, we choose the second.

## 2.5 Changing the Grammar without Changing the Program
We show the utility（效用） of approach  (2)  by defining a new grammar that includes 
adjectives, prepositional phrases, proper names（专有名词）, and pronouns（代词）. We can then apply the
generate function without modification to this new grammar.
generate函数不做修改就可以应用到下面的新语法：

(defparameter *bigger-grammar*
  '((sentence -> (noun-phrase verb-phrase))
    (noun-phrase -> (Article Adj* Noun PP*) (Name) (Pronoun))
    (verb-phrase -> (Verb noun-phrase PP*))
    (PP* -> () (PP PP*))
    (Adj* -> () (Adj Adj*))
    (PP -> (Prep noun-phrase))
    (Prep -> to in by with on)
    (Adj -> big little blue green adiabatic)
    (Article -> the a)
    (Name -> Pat Kim Lee Terry Robin)
    (Noun -> man ball woman table)
    (Verb -> hit took saw liked)
    (Pronoun -> he she it these those that)))

(setf *grammar* *big-grammar*)

>  (generate 'sentence)
(A TABLE ON A TABLE IN THE BLUE ADIABATIC MAN SAW ROBIN
WITH A LITTLE WOMAN)
>  (generate 'sentence)
(TERRY SAW A ADIABATIC TABLE ON THE GREEN BALL BY THAT WITH KIM
IN THESE BY A GREEN WOMAN BY A LITTLE ADIABATIC TABLE IN ROBIN
ON LEE)
>  (generate 'sentence)
(THE GREEN TABLE HIT IT WITH HE)
Notice the problem with case agreement for pronouns: the program generated "with
he, " although "with him" is the proper grammatical form. Also, it is clear that the
program does not distinguish sensible from silly output.

## 2.6  Using the Same Data for Several Programs
Another advantage of representing information in a declarative form - as rules or
facts rather than as Lisp functions - is that it can be easier to use the information for
multiple purposes. Suppose we wanted a function that would generate not just the
list of words in a sentence but a representation of the complete syntax of a sentence.
For example, instead of the list  (a woman took a ball),  we want to get the nested list:

(SENTENCE (NOUN-PHRASE (ARTICLE A) (NOUN WOMAN))
          (VERB-PHRASE (VERB TOOK)
                       (NOUN-PHRASE (ARTICLE A) (NOUN BALL))))


Using the "straightforward functions" approach we would be stuck; we'd have to
rewrite every function to generate the additional structure. With the "new notation"
approach we could keep the grammar as it is and just write one new function: a
version of generate that produces nested lists. The two changes are to cons the
category onto the front of each rewrite, and then not to append together the results
but rather just list them with mapcar:

(defun generate-tree (phrase)
"Generate a random sentence or phrase
with a complete parse tree."
  (cond ((listp phrase)
            (mapcar #'generate-tree phrase))
        ((rewrites phrase)
            (cons phrase
                  (generate (random-elt (rewrites phrase)))))
        (t (list phrase))))


Exercise 2.3 [h]  Write a trivial grammar for some other language. This can be a
natural language other than English, or perhaps a subset of a computer language.

Exercise 2.4 [rn] One way of describing combine-all is that it calculates the cross-product 
of the function append on the argument lists. Write the higher-order function
cross-product, and define combine-all in terms of it.
The moral is to make your code as general as possible, because you never know what
you may want to do with it next.

;;
;;
